# 大数据开发规范 - CODING-STANDARDS-BIG-DATA

**版本**: 2.0.0
**适用范围**: 大数据开发岗位（批处理/流处理/数据湖/数据仓库，技术栈无关）
**最后更新**: 2025-12-25

---

## 🚨 核心铁律（继承自 common.md）

> **必须遵循 common.md 的四大核心铁律**

```
铁律1: SPEC 是唯一真源（SSOT）
       - 数据管道设计必须符合 SPEC 定义
       - Schema、数据流、处理逻辑以 SPEC 为准

铁律2: 智能复用与销毁重建
       - 现有管道完全匹配 → 直接复用
       - 部分匹配 → 删除重建

铁律3: 禁止渐进式开发
       - 禁止在旧管道上添加新功能
       - 禁止保留兼容性 Schema

铁律4: Context7 调研先行
       - 使用成熟的大数据框架
       - 禁止自己实现 ETL 工具
```

---

## 🏗️ 数据管道设计

### 管道原则
- ✅ 单一职责：每个作业只做一件事
- ✅ 幂等性：重复执行产生相同结果
- ✅ 可重启性：支持从失败点恢复
- ✅ 明确数据血缘关系
- ❌ 避免管道间强耦合

### 数据流设计
- ✅ 明确输入、处理、输出边界
- ✅ 使用检查点机制
- ✅ 设计数据回填策略
- ✅ 区分增量处理和全量处理
- ✅ 处理延迟数据（Late Data）
- ❌ 避免循环依赖

---

## 📊 批处理开发

### 作业设计
- ✅ 数据分区（按时间/区域/业务）
- ✅ 合理设置批次大小
- ✅ 并行度与资源匹配
- ✅ 失败任务可重试
- ✅ 中间结果持久化
- ❌ 避免单点瓶颈

### 调度管理
- ✅ 明确作业依赖关系（DAG）
- ✅ 设置合理的超时时间
- ✅ 配置告警和监控
- ✅ 区分正常失败和异常失败
- ✅ 记录作业运行历史
- ❌ 避免硬编码调度时间

### 数据质量
- ✅ 输入数据验证（Schema、范围、完整性）
- ✅ 处理过程中数据质量检查
- ✅ 输出数据一致性验证
- ✅ 异常数据隔离（坏数据分区）
- ✅ 数据质量指标监控

---

## ⚡ 流处理开发

### 流处理原则
- ✅ 处理无界数据流
- ✅ 事件时间 vs 处理时间
- ✅ 窗口机制（滚动/滑动/会话窗口）
- ✅ 水位线（Watermark）处理延迟数据
- ✅ 状态管理和检查点
- ❌ 避免状态无限增长

### 实时性保证
- ✅ 明确延迟要求（秒级/分钟级）
- ✅ 反压机制（Backpressure）
- ✅ 流量控制和限流
- ✅ 监控处理延迟
- ❌ 避免阻塞操作

### 一致性保证
- ✅ 至少一次（At Least Once）vs 精确一次（Exactly Once）
- ✅ 事务性输出
- ✅ 去重机制
- ✅ 顺序保证（分区内有序）
- ✅ 幂等性设计

---

## 🗂️ 数据分区和存储

### 分区策略
- ✅ 按时间分区（年/月/日/小时）
- ✅ 按业务维度分区（地区/类别）
- ✅ 避免数据倾斜
- ✅ 分区剪枝优化查询
- ✅ 合理控制分区数量（< 10000）
- ❌ 避免小文件问题

### 文件格式
- ✅ 使用列式存储（Parquet、ORC）
- ✅ 启用压缩（Snappy、ZSTD）
- ✅ Schema演化兼容性
- ✅ 文件大小合理（128MB-1GB）
- ❌ 避免使用纯文本格式（生产环境）

### 数据生命周期
- ✅ 定义数据保留策略
- ✅ 冷热数据分层存储
- ✅ 自动归档历史数据
- ✅ 过期数据清理
- ✅ 成本优化存储

---

## 🔄 Schema管理

### Schema设计
- ✅ 向后兼容的Schema演化
- ✅ 使用Schema注册中心
- ✅ 版本化管理Schema
- ✅ 明确字段类型和约束
- ❌ 避免破坏性变更

### 数据类型
- ✅ 使用合适的数据类型（减少存储和计算成本）
- ✅ 嵌套结构合理使用（避免过深）
- ✅ 时间戳统一使用UTC
- ✅ 字符串字段设置长度限制
- ❌ 避免使用动态类型（影响性能）

---

## ⚙️ 资源管理

### 资源配置
- ✅ 根据数据量配置内存
- ✅ 合理设置并行度
- ✅ CPU和IO平衡
- ✅ 资源隔离（任务间不互相影响）
- ✅ 弹性扩缩容
- ❌ 避免资源过度配置

### 性能优化
- ✅ 减少数据Shuffle
- ✅ 使用广播变量（小表关联）
- ✅ 本地聚合减少网络传输
- ✅ 缓存重复使用的数据集
- ✅ 谓词下推（Predicate Pushdown）
- ✅ 列剪裁（Column Pruning）

### 成本优化
- ✅ 使用竞价实例（非关键作业）
- ✅ 按需启动停止集群
- ✅ 监控资源使用率
- ✅ 优化数据存储成本
- ❌ 避免资源闲置浪费

---

## 🛡️ 数据安全

### 访问控制
- ✅ 最小权限原则
- ✅ 数据分级分类管理
- ✅ 敏感数据加密存储
- ✅ 审计日志记录
- ❌ 禁止明文存储敏感数据

### 数据脱敏
- ✅ 生产数据脱敏后用于开发测试
- ✅ 敏感字段哈希或加密
- ✅ PII数据（个人身份信息）保护
- ✅ 数据导出权限控制

---

## 📈 监控和可观测性

### 监控指标
- ✅ 作业执行时长
- ✅ 数据处理量
- ✅ 资源使用率（CPU/内存/磁盘/网络）
- ✅ 错误率和重试次数
- ✅ 数据延迟（流处理）
- ✅ 数据质量指标

### 告警机制
- ✅ 作业失败告警
- ✅ 数据延迟超阈值告警
- ✅ 数据质量异常告警
- ✅ 资源使用异常告警
- ✅ SLA违反告警

### 日志和追踪
- ✅ 结构化日志
- ✅ 关键操作记录日志
- ✅ 分布式追踪（Trace ID）
- ✅ 数据血缘追踪
- ❌ 避免日志泛滥（过度记录）

---

## 🧪 测试

### 测试策略
- ✅ 单元测试（数据转换逻辑）
- ✅ 集成测试（端到端管道）
- ✅ 数据质量测试
- ✅ 性能测试（大数据量）
- ✅ 边界测试（空数据、坏数据）

### 测试数据
- ✅ 使用生产数据采样
- ✅ 合成数据生成
- ✅ 测试环境数据隔离
- ✅ 模拟数据倾斜场景
- ❌ 禁止在生产环境测试

---

## 📋 大数据开发检查清单

- [ ] 管道幂等性和可重启性
- [ ] 数据分区合理（避免小文件和数据倾斜）
- [ ] Schema版本管理和兼容性
- [ ] 资源配置合理（内存、并行度）
- [ ] 数据质量验证
- [ ] 监控和告警配置
- [ ] 敏感数据加密和脱敏
- [ ] 日志和追踪完整
- [ ] 失败重试和容错机制
- [ ] 成本优化（存储、计算）

---

---

## 🏛️ 高级数据架构（20+年经验）

### 现代数据架构范式
```
数据网格（Data Mesh）：
- 领域所有权：数据由领域团队拥有
- 数据即产品：数据作为产品发布
- 自服务平台：统一基础设施
- 联邦治理：去中心化治理
- 适用：大型组织，多领域

数据湖仓（Lakehouse）：
- 结合数据湖和数据仓库优势
- Delta Lake/Iceberg/Hudi 表格式
- ACID 事务支持
- Schema 演化和时间旅行
- 统一批流处理

Lambda vs Kappa 架构：
- Lambda：批处理 + 流处理双路
- Kappa：仅流处理，统一架构
- 选择考量：复杂度 vs 一致性
```

### 流批一体架构
```
统一处理引擎：
- Apache Flink：流批统一
- Apache Beam：跨引擎抽象
- Spark Structured Streaming：微批+流

实时数仓：
- ODS（操作数据层）：实时入湖
- DWD（明细数据层）：实时清洗
- DWS（汇总数据层）：实时聚合
- ADS（应用数据层）：实时服务

实时特性：
- 增量计算（Incremental Processing）
- 物化视图（Materialized Views）
- 变更数据捕获（CDC）
```

### 数据治理架构
```
元数据管理：
- Apache Atlas：血缘追踪
- DataHub：元数据平台
- Amundsen：数据发现

数据质量框架：
- Great Expectations：数据验证
- Deequ：Spark 数据质量
- 数据契约（Data Contracts）

数据目录：
- 自动化发现
- 业务术语表
- 敏感数据分类
- 数据资产搜索
```

---

## 🔧 资深大数据专家必备技巧

### Spark 深度优化
```
内存管理：
- Executor Memory = Heap + Off-Heap
- spark.memory.fraction 调优
- 序列化（Kryo vs Java）
- 广播变量大小控制

Shuffle 优化：
- spark.sql.shuffle.partitions 调优
- AQE（Adaptive Query Execution）
- Coalesce vs Repartition
- 倾斜处理（Salting）

执行计划优化：
- 谓词下推验证
- Join 策略选择（Broadcast/Sort-Merge/Shuffle-Hash）
- CBO（Cost-Based Optimizer）
- Catalyst 优化器理解
```

### Flink 深度优化
```
状态管理：
- 状态后端选择（Memory/RocksDB）
- 增量检查点
- 状态TTL
- 状态规模控制

反压处理：
- 识别反压源
- Buffer 调优
- 并行度调整
- 异步IO

Exactly-Once 语义：
- 两阶段提交（2PC）
- 幂等写入
- 事务性 Sink
- Changelog Stream
```

### 性能调优方法论
```
问题诊断：
1. 确认瓶颈（CPU/Memory/IO/Network）
2. 分析执行计划
3. 识别数据倾斜
4. 检查资源配置

调优策略：
- 数据层面：分区、压缩、格式
- 算子层面：并行度、内存、Shuffle
- 集群层面：资源分配、队列配置
- 代码层面：避免 UDF、使用向量化
```

### 成本优化实践
```
存储成本：
- 冷热分层（S3 Glacier）
- 列式压缩（ZSTD/LZ4）
- 数据生命周期管理
- 小文件合并

计算成本：
- Spot/Preemptible 实例
- 弹性扩缩容
- 资源利用率优化
- 作业调度优化

FinOps 实践：
- 成本归因（按团队/项目）
- 预算告警
- 资源使用报告
- 持续优化循环
```

---

## 🚨 资深大数据专家常见陷阱

### 架构陷阱
```
❌ 过度实时化：
- 所有场景都用流处理
- 增加复杂度和成本
- 正确做法：根据时效性需求选择

❌ 忽视数据质量：
- 只关注管道功能
- 脏数据污染下游
- 正确做法：数据质量检查门禁

❌ Schema 野蛮增长：
- 字段随意添加
- 无版本管理
- 正确做法：Schema Registry，兼容性检查
```

### 性能陷阱
```
❌ 数据倾斜不处理：
- Join 键分布不均
- 单 Task 拖累整体
- 正确做法：Salting、Broadcast、AQE

❌ 小文件泛滥：
- 高频写入产生大量小文件
- 元数据压力大，查询慢
- 正确做法：合并作业，Compaction

❌ 过度分区：
- 分区数过多
- 查询反而变慢
- 正确做法：合理分区粒度，< 10000
```

### 运维陷阱
```
❌ 检查点不可靠：
- 检查点失败不告警
- 故障时无法恢复
- 正确做法：检查点监控，备份验证

❌ 资源过度配置：
- 每个作业都配大内存
- 资源浪费严重
- 正确做法：按需配置，动态资源分配

❌ 忽视回填场景：
- 只考虑增量处理
- 历史数据无法处理
- 正确做法：设计回填策略
```

---

## 📊 性能监控指标

| 指标 | 目标值 | 告警阈值 | 测量工具 |
|------|--------|----------|----------|
| 作业成功率 | > 99% | < 95% | 调度系统 |
| 数据延迟（流处理） | < 1分钟 | > 5分钟 | 监控系统 |
| 处理吞吐量 | 根据SLA | < 80% 预期 | Metrics |
| 检查点成功率 | 100% | < 99% | Flink Dashboard |
| 数据质量通过率 | > 99.9% | < 99% | 质量平台 |
| 资源利用率 | 60-80% | < 30% 或 > 90% | 集群监控 |
| Shuffle 数据量 | 根据作业 | 异常增长 | Spark UI |
| GC 时间占比 | < 5% | > 10% | JVM 监控 |
| 小文件数量 | < 1000/分区 | > 5000 | 存储监控 |
| 数据倾斜比 | < 2x | > 10x | 执行计划 |

---

## 📋 大数据开发检查清单（完整版）

### 管道设计
- [ ] 幂等性和可重启性
- [ ] 回填策略设计
- [ ] 数据血缘记录
- [ ] 延迟数据处理

### 性能优化
- [ ] 分区策略合理
- [ ] 无数据倾斜
- [ ] 无小文件问题
- [ ] Shuffle 优化

### 数据质量
- [ ] 输入验证
- [ ] 过程中检查
- [ ] 输出验证
- [ ] 异常数据隔离

### 运维保障
- [ ] 监控和告警
- [ ] 日志和追踪
- [ ] 检查点可靠
- [ ] 成本优化

---

**大数据开发原则总结**：
幂等性、可重启性、数据质量、分区优化、资源管理、监控告警、Schema演化、流批一体、成本优化、数据安全
