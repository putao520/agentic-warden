#!/usr/bin/env python3
"""
Agentic-Warden æµ‹è¯•éªŒè¯è„šæœ¬
éªŒè¯æµ‹è¯•çš„å®Œæ•´æ€§å’Œè´¨é‡
"""

import os
import sys
import json
import subprocess
import argparse
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum

class TestStatus(Enum):
    PASSED = "passed"
    FAILED = "failed"
    SKIPPED = "skipped"

@dataclass
class TestResult:
    name: str
    status: TestStatus
    duration: float
    output: str
    error: Optional[str] = None

@dataclass
class ValidationReport:
    total_tests: int
    passed_tests: int
    failed_tests: int
    skipped_tests: int
    coverage: Optional[float] = None
    results: List[TestResult] = None

class TestValidator:
    def __init__(self, project_root: Path):
        self.project_root = project_root
        self.output_dir = project_root / "test-results"
        self.results: List[TestResult] = []

    def validate_all(self) -> ValidationReport:
        """éªŒè¯æ‰€æœ‰æµ‹è¯•"""
        print("ğŸ” å¼€å§‹éªŒè¯æµ‹è¯•...")

        # è¿è¡Œå„ç±»æµ‹è¯•
        self._run_unit_tests()
        self._run_integration_tests()
        self._run_cli_tests()
        self._validate_test_coverage()
        self._check_test_quality()
        self._validate_mock_coverage()

        return self._generate_report()

    def _run_unit_tests(self) -> None:
        """è¿è¡Œå•å…ƒæµ‹è¯•"""
        print("ğŸ“¦ è¿è¡Œå•å…ƒæµ‹è¯•...")
        result = self._run_command(
            ["cargo", "test", "--lib", "--message-format=json"],
            "unit_tests"
        )
        self.results.append(result)

    def _run_integration_tests(self) -> None:
        """è¿è¡Œé›†æˆæµ‹è¯•"""
        print("ğŸ”— è¿è¡Œé›†æˆæµ‹è¯•...")
        result = self._run_command(
            ["cargo", "test", "--test", "integration", "--message-format=json"],
            "integration_tests"
        )
        self.results.append(result)

    def _run_cli_tests(self) -> None:
        """è¿è¡ŒCLIæµ‹è¯•"""
        print("ğŸ’» è¿è¡ŒCLIæµ‹è¯•...")
        result = self._run_command(
            ["cargo", "test", "--test", "cli_integration", "--message-format=json"],
            "cli_tests"
        )
        self.results.append(result)

    def _run_command(self, cmd: List[str], test_name: str) -> TestResult:
        """è¿è¡Œå‘½ä»¤å¹¶è¿”å›ç»“æœ"""
        try:
            start_time = os.time.time()
            result = subprocess.run(
                cmd,
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=300
            )
            duration = os.time.time() - start_time

            # è§£æJSONè¾“å‡º
            if result.returncode == 0:
                status = TestStatus.PASSED
                error = None
            else:
                status = TestStatus.FAILED
                error = result.stderr

            # å°è¯•è§£æJSONæ ¼å¼çš„æµ‹è¯•è¾“å‡º
            test_count = 0
            passed_count = 0
            if result.stdout:
                try:
                    lines = result.stdout.strip().split('\n')
                    for line in lines:
                        if line.strip().startswith('{'):
                            data = json.loads(line)
                            if data.get('type') == 'test':
                                test_count += 1
                                if data.get('event') == 'passed':
                                    passed_count += 1
                except json.JSONDecodeError:
                    pass

            output = f"Tests: {passed_count}/{test_count} passed\n"
            output += f"Duration: {duration:.2f}s\n"
            if result.stdout:
                output += f"Output: {result.stdout[:500]}"

            return TestResult(
                name=test_name,
                status=status,
                duration=duration,
                output=output,
                error=error
            )

        except subprocess.TimeoutExpired:
            return TestResult(
                name=test_name,
                status=TestStatus.FAILED,
                duration=300.0,
                output="",
                error="Test timeout"
            )
        except Exception as e:
            return TestResult(
                name=test_name,
                status=TestStatus.FAILED,
                duration=0.0,
                output="",
                error=str(e)
            )

    def _validate_test_coverage(self) -> None:
        """éªŒè¯æµ‹è¯•è¦†ç›–ç‡"""
        print("ğŸ“Š éªŒè¯æµ‹è¯•è¦†ç›–ç‡...")

        try:
            # æ£€æŸ¥æ˜¯å¦å®‰è£…äº†cargo-llvm-cov
            result = subprocess.run(
                ["cargo", "llvm-cov", "--workspace", "--html", "--output-dir", "coverage"],
                cwd=self.project_root,
                capture_output=True,
                text=True,
                timeout=600
            )

            if result.returncode == 0:
                # å°è¯•æå–è¦†ç›–ç‡ä¿¡æ¯
                coverage = self._extract_coverage()
                print(f"âœ… ä»£ç è¦†ç›–ç‡: {coverage:.1f}%")
            else:
                print("âš ï¸  è¦†ç›–ç‡æŠ¥å‘Šç”Ÿæˆå¤±è´¥")

        except Exception as e:
            print(f"âš ï¸  è¦†ç›–ç‡æ£€æŸ¥å¤±è´¥: {e}")

    def _extract_coverage(self) -> float:
        """ä»è¦†ç›–ç‡æŠ¥å‘Šä¸­æå–è¦†ç›–ç‡ç™¾åˆ†æ¯”"""
        try:
            # æŸ¥æ‰¾HTMLè¦†ç›–ç‡æŠ¥å‘Š
            coverage_dir = self.project_root / "target" / "llvm-cov" / "html"
            index_file = coverage_dir / "index.html"

            if index_file.exists():
                content = index_file.read_text()
                # ç®€å•çš„è¦†ç›–ç‡æå–ï¼ˆå®é™…å®ç°å¯èƒ½éœ€è¦æ›´å¤æ‚çš„è§£æï¼‰
                if "%" in content:
                    # æŸ¥æ‰¾è¦†ç›–ç‡ç™¾åˆ†æ¯”
                    import re
                    matches = re.findall(r'(\d+\.\d+)%', content)
                    if matches:
                        return float(matches[-1])  # å–æœ€åä¸€ä¸ªåŒ¹é…é¡¹

            return 0.0
        except Exception:
            return 0.0

    def _check_test_quality(self) -> None:
        """æ£€æŸ¥æµ‹è¯•è´¨é‡æŒ‡æ ‡"""
        print("ğŸ” æ£€æŸ¥æµ‹è¯•è´¨é‡...")

        # æ£€æŸ¥æµ‹è¯•æ–‡ä»¶æ•°é‡
        test_files = list(self.project_root.glob("**/*tests*.rs"))
        lib_tests = list(self.project_root.glob("**/tests/**/*.rs"))
        integration_tests = list(self.project_root.glob("tests/**/*.rs"))

        print(f"ğŸ“ æµ‹è¯•æ–‡ä»¶ç»Ÿè®¡:")
        print(f"  - æ¨¡å—æµ‹è¯•æ–‡ä»¶: {len(test_files)}")
        print(f"  - åº“æµ‹è¯•æ–‡ä»¶: {len(lib_tests)}")
        print(f"  - é›†æˆæµ‹è¯•æ–‡ä»¶: {len(integration_tests)}")

        # æ£€æŸ¥æµ‹è¯•å‘½åè§„èŒƒ
        self._check_test_naming(test_files + lib_tests + integration_tests)

        # æ£€æŸ¥æµ‹è¯•æ–‡æ¡£
        self._check_test_documentation(test_files + lib_tests + integration_tests)

    def _check_test_naming(self, test_files: List[Path]) -> None:
        """æ£€æŸ¥æµ‹è¯•å‘½åè§„èŒƒ"""
        naming_issues = []

        for file_path in test_files:
            try:
                content = file_path.read_text(encoding='utf-8')
                lines = content.split('\n')

                for i, line in enumerate(lines, 1):
                    # æ£€æŸ¥æµ‹è¯•å‡½æ•°å‘½å
                    if 'fn test_' in line or '#[test]' in line:
                        if 'fn test_' in line:
                            func_name = line.strip().split('fn test_')[1].split('(')[0]

                            # æ£€æŸ¥å‘½åè§„èŒƒï¼ˆshould_å¼€å¤´æˆ–æè¿°æ€§å‘½åï¼‰
                            if not (func_name.startswith('should_') or
                                   func_name.startswith('test_') or
                                   '_' in func_name or
                                   len(func_name) >= 5):
                                naming_issues.append(f"{file_path}:{i} - {func_name}")

            except Exception:
                continue

        if naming_issues:
            print("âš ï¸  å‘ç°æµ‹è¯•å‘½åé—®é¢˜:")
            for issue in naming_issues[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"  - {issue}")
            if len(naming_issues) > 10:
                print(f"  - ...è¿˜æœ‰ {len(naming_issues) - 10} ä¸ªé—®é¢˜")
        else:
            print("âœ… æµ‹è¯•å‘½åè§„èŒƒæ£€æŸ¥é€šè¿‡")

    def _check_test_documentation(self, test_files: List[Path]) -> None:
        """æ£€æŸ¥æµ‹è¯•æ–‡æ¡£"""
        undocumented_tests = []

        for file_path in test_files:
            try:
                content = file_path.read_text(encoding='utf-8')
                lines = content.split('\n')

                in_test = False
                for i, line in enumerate(lines, 1):
                    if '#[test]' in line:
                        in_test = True
                        continue

                    if in_test and 'fn test_' in line:
                        # æ£€æŸ¥æµ‹è¯•å‡½æ•°å‰æ˜¯å¦æœ‰æ–‡æ¡£æ³¨é‡Š
                        has_doc = False
                        for j in range(max(0, i-3), i):
                            if '///' in lines[j] or '/**' in lines[j]:
                                has_doc = True
                                break

                        if not has_doc:
                            func_name = line.strip().split('fn test_')[1].split('(')[0]
                            undocumented_tests.append(f"{file_path}:{i} - {func_name}")

                        in_test = False

            except Exception:
                continue

        if undocumented_tests:
            print("âš ï¸  å‘ç°æœªæ–‡æ¡£åŒ–çš„æµ‹è¯•:")
            for test in undocumented_tests[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"  - {test}")
            if len(undocumented_tests) > 5:
                print(f"  - ...è¿˜æœ‰ {len(undocumented_tests) - 5} ä¸ªæœªæ–‡æ¡£åŒ–çš„æµ‹è¯•")
        else:
            print("âœ… æµ‹è¯•æ–‡æ¡£æ£€æŸ¥é€šè¿‡")

    def _validate_mock_coverage(self) -> None:
        """éªŒè¯Mockè¦†ç›–ç‡"""
        print("ğŸ­ éªŒè¯Mockè¦†ç›–ç‡...")

        # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„Mockå¯¹è±¡
        mock_files = list(self.project_root.glob("**/*mock*.rs"))
        test_util_files = list(self.project_root.glob("**/test_utils/**/*.rs"))

        print(f"ğŸ“ Mockæ–‡ä»¶ç»Ÿè®¡:")
        print(f"  - Mockå®ç°æ–‡ä»¶: {len(mock_files)}")
        print(f"  - æµ‹è¯•å·¥å…·æ–‡ä»¶: {len(test_util_files)}")

        # æ£€æŸ¥å…³é”®å¤–éƒ¨ä¾èµ–æ˜¯å¦è¢«Mock
        critical_deps = [
            'google_drive', 'oauth', 'http', 'network', 'filesystem'
        ]

        for dep in critical_deps:
            mock_found = False
            for mock_file in mock_files + test_util_files:
                try:
                    content = mock_file.read_text(encoding='utf-8')
                    if dep.lower() in content.lower():
                        mock_found = True
                        break
                except Exception:
                    continue

            if mock_found:
                print(f"  âœ… {dep} - å·²Mock")
            else:
                print(f"  âš ï¸  {dep} - ç¼ºå°‘Mock")

    def _generate_report(self) -> ValidationReport:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        total = len(self.results)
        passed = sum(1 for r in self.results if r.status == TestStatus.PASSED)
        failed = sum(1 for r in self.results if r.status == TestStatus.FAILED)
        skipped = sum(1 for r in self.results if r.status == TestStatus.SKIPPED)

        report = ValidationReport(
            total_tests=total,
            passed_tests=passed,
            failed_tests=failed,
            skipped_tests=skipped,
            results=self.results
        )

        # æ‰“å°æ€»ç»“
        print("\n" + "="*50)
        print("ğŸ“Š æµ‹è¯•éªŒè¯æ€»ç»“")
        print("="*50)
        print(f"æ€»æµ‹è¯•å¥—ä»¶: {total}")
        print(f"âœ… é€šè¿‡: {passed}")
        print(f"âŒ å¤±è´¥: {failed}")
        print(f"â­ï¸  è·³è¿‡: {skipped}")

        if passed == total:
            print("ğŸ‰ æ‰€æœ‰æµ‹è¯•éªŒè¯é€šè¿‡!")
        else:
            print("ğŸ’¥ éƒ¨åˆ†æµ‹è¯•éªŒè¯å¤±è´¥!")

        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šæ–‡ä»¶
        self._save_report_to_file(report)

        return report

    def _save_report_to_file(self, report: ValidationReport) -> None:
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        report_file = self.output_dir / "validation_report.json"
        report_file.parent.mkdir(exist_ok=True)

        report_data = {
            "total_tests": report.total_tests,
            "passed_tests": report.passed_tests,
            "failed_tests": report.failed_tests,
            "skipped_tests": report.skipped_tests,
            "results": [
                {
                    "name": r.name,
                    "status": r.status.value,
                    "duration": r.duration,
                    "error": r.error
                }
                for r in report.results
            ]
        }

        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)

        print(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")

def main():
    parser = argparse.ArgumentParser(description="Agentic-Warden æµ‹è¯•éªŒè¯è„šæœ¬")
    parser.add_argument(
        "--project-root",
        type=Path,
        default=Path.cwd(),
        help="é¡¹ç›®æ ¹ç›®å½•è·¯å¾„"
    )
    parser.add_argument(
        "--output",
        type=Path,
        help="è¾“å‡ºç›®å½•è·¯å¾„"
    )

    args = parser.parse_args()

    # è®¾ç½®è¾“å‡ºç›®å½•
    if args.output:
        output_dir = args.output
    else:
        output_dir = args.project_root / "test-results"

    # åˆ›å»ºéªŒè¯å™¨å¹¶è¿è¡Œ
    validator = TestValidator(args.project_root)
    report = validator.validate_all()

    # è®¾ç½®é€€å‡ºç 
    sys.exit(0 if report.failed_tests == 0 else 1)

if __name__ == "__main__":
    main()