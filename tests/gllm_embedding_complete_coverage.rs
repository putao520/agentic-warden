//! Complete gllm embedding test coverage - 100% test scenarios
//! Includes edge cases, error handling, and advanced scenarios

#[cfg(test)]
mod tests {
    use memvdb::normalize;
use std::sync::{Arc, Barrier};
use std::thread;

    #[test]
    fn test_empty_text_embedding() {
        println!("\nðŸ“‹ Test 1: Empty Text Embedding");

        let client = gllm::Client::new("all-MiniLM-L6-v2")
            .expect("Failed to create gllm client");

        let empty_text = "";

        match client.embeddings(&[empty_text.to_string()]).generate() {
            Ok(response) => {
                if let Some(emb) = response.embeddings.into_iter().next() {
                    let vector = normalize(&emb.embedding);
                    println!("âœ… Empty text embedding generated: {} dimensions", vector.len());
                    assert_eq!(vector.len(), 384, "Empty text should still produce 384 dimensions");
                    assert!(vector.iter().any(|x| !x.is_nan()), "Vector should not contain NaN values");
                } else {
                    panic!("No embedding generated for empty text");
                }
            }
            Err(e) => panic!("Empty text embedding failed: {}", e),
        }
    }

    #[test]
    fn test_unicode_text_embedding() {
        println!("\nðŸ“‹ Test 2: Unicode/Emoji Text Embedding");

        let client = gllm::Client::new("all-MiniLM-L6-v2")
            .expect("Failed to create gllm client");

        let unicode_texts = vec![
            "Hello ðŸ˜Š World ðŸŒ",
            "æµ‹è¯• âœ… ä¸­æ–‡ ðŸ‡¨ðŸ‡³",
            "ã“ã‚“ã«ã¡ã¯ ðŸ‡¯ðŸ‡µ World",
            "Ù…Ø±Ø­Ø¨Ø§ ðŸ‡¸ðŸ‡¦ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…",
            "C++ ðŸ“š Rust ðŸ¦€ Python ðŸ",
        ];

        for (idx, text) in unicode_texts.iter().enumerate() {
            match client.embeddings(&[text.to_string()]).generate() {
                Ok(response) => {
                    if let Some(emb) = response.embeddings.into_iter().next() {
                        let vector = normalize(&emb.embedding);
                        println!("âœ… Unicode test #{}: {} dimensions", idx + 1, vector.len());
                        assert_eq!(vector.len(), 384, "Unicode text should produce 384 dimensions");
                        assert!(!vector.is_empty(), "Unicode vector should not be empty");
                    } else {
                        panic!("No embedding generated for unicode text: {}", text);
                    }
                }
                Err(e) => panic!("Unicode embedding failed for '{}': {}", text, e),
            }
        }

        println!("âœ… All unicode embeddings handled correctly");
    }

    #[test]
    fn test_long_text_embedding() {
        println!("\nðŸ“‹ Test 3: Long Text Embedding (512+ tokens)");

        let client = gllm::Client::new("all-MiniLM-L6-v2")
            .expect("Failed to create gllm client");

        let long_text = "
        Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.
        Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.
        Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.
        Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

        Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.
        Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.
        Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.
        Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

        Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.
        Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.
        Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur.
        Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.
        ";

        match client.embeddings(&[long_text.to_string()]).generate() {
            Ok(response) => {
                if let Some(emb) = response.embeddings.into_iter().next() {
                    let vector = normalize(&emb.embedding);
                    println!("âœ… Long text embedding: {} dimensions, {:.0} chars", vector.len(), long_text.len());
                    assert_eq!(vector.len(), 384, "Long text should still produce 384 dimensions");
                    assert!(!vector.iter().all(|x| *x == 0.0), "Long text vector should not be all zeros");
                } else {
                    panic!("No embedding generated for long text");
                }
            }
            Err(e) => panic!("Long text embedding failed: {}", e),
        }
    }

    #[test]
    fn test_repeated_text_embedding() {
        println!("\nðŸ“‹ Test 4: Repeated/Duplicate Text Embedding");

        let client = gllm::Client::new("all-MiniLM-L6-v2")
            .expect("Failed to create gllm client");

        let repeated_text = "test test test test test test test test test test";

        // Generate embedding multiple times for the same repeated text
        let embeddings: Vec<Vec<f32>> = (0..3)
            .map(|i| {
                let response = client.embeddings(&[repeated_text.to_string()]).generate()
                    .expect("Repeated text embedding failed");
                response.embeddings.into_iter().next()
                    .expect("No embedding generated")
                    .embedding
            })
            .map(|v| normalize(&v))
            .collect();

        // Check all embeddings have same dimension
        for embedding in &embeddings {
            assert_eq!(embedding.len(), 384, "All repeated text embeddings should be 384 dimensions");
        }

        // Check if embeddings are consistent (should be very similar)
        let first_norm = &embeddings[0];
        let second_norm = &embeddings[1];
        let third_norm = &embeddings[2];

        let similarity1 = first_norm.iter().zip(second_norm.iter())
            .map(|(a, b)| a * b).sum::<f32>();
        let similarity2 = first_norm.iter().zip(third_norm.iter())
            .map(|(a, b)| a * b).sum::<f32>();

        println!("âœ… Repeated text embeddings generated:");
        println!("   Similarity 1-2: {:.6}", similarity1);
        println!("   Similarity 1-3: {:.6}", similarity2);

        // Same text should produce very similar embeddings
        assert!(similarity1 > 0.95, "Repeated text embeddings should be very similar");
        assert!(similarity2 > 0.95, "Repeated text embeddings should be very similar");
    }

    #[test]
    fn test_special_characters_embedding() {
        println!("\nðŸ“‹ Test 5: Special Characters and Punctuation");

        let client = gllm::Client::new("all-MiniLM-L6-v2")
            .expect("Failed to create gllm client");

        let special_texts = vec![
            "Hello!!! World???",
            "Yes/No - Maybe...",
            "123 Numbers 456",
            "@mentions #hashtags $symbols",
            "(parentheses) [brackets] {braces}",
            "line1\nline2\r\nline3",
            "tab\tseparated\ttext",
            "multiple    spaces    between",
        ];

        for (idx, text) in special_texts.iter().enumerate() {
            match client.embeddings(&[text.to_string()]).generate() {
                Ok(response) => {
                    if let Some(emb) = response.embeddings.into_iter().next() {
                        let vector = normalize(&emb.embedding);
                        println!("âœ… Special chars test #{}: '{}' - {} dimensions", idx + 1, text, vector.len());
                        assert_eq!(vector.len(), 384, "Special chars text should produce 384 dimensions");
                    } else {
                        panic!("No embedding generated for: {}", text);
                    }
                }
                Err(e) => panic!("Special chars embedding failed for '{}': {}", text, e),
            }
        }
    }

    #[test]
    fn test_single_character_embedding() {
        println!("\nðŸ“‹ Test 6: Single Character Embedding");

        let client = gllm::Client::new("all-MiniLM-L6-v2")
            .expect("Failed to create gllm client");

        let single_chars = vec!["A", "B", "C", "1", "2", "3", "@", "#", "$"];

        for ch in single_chars {
            match client.embeddings(&[ch.to_string()]).generate() {
                Ok(response) => {
                    if let Some(emb) = response.embeddings.into_iter().next() {
                        let vector = normalize(&emb.embedding);
                        println!("âœ… Single char '{}' embedding: {} dimensions", ch, vector.len());
                        assert_eq!(vector.len(), 384, "Single character should produce 384 dimensions");
                    } else {
                        panic!("No embedding generated for: {}", ch);
                    }
                }
                Err(e) => panic!("Single char embedding failed for '{}': {}", ch, e),
            }
        }
    }

    #[test]
    fn test_embedding_vector_properties() {
        println!("\nðŸ“‹ Test 7: Vector Properties Validation");

        let client = gllm::Client::new("all-MiniLM-L6-v2")
            .expect("Failed to create gllm client");

        let text = "Vector properties test";

        let response = client.embeddings(&[text.to_string()]).generate()
            .expect("Embedding generation failed");

        if let Some(emb) = response.embeddings.into_iter().next() {
            let vector = normalize(&emb.embedding);

            // Test vector properties
            let magnitude = vector.iter().map(|x| x * x).sum::<f32>().sqrt();
            let has_nan = vector.iter().any(|x| x.is_nan());
            let has_inf = vector.iter().any(|x| x.is_infinite());
            let is_finite = vector.iter().all(|x| x.is_finite());
            let max_value = vector.iter().fold(f32::MIN, |max, x| max.max(*x));
            let min_value = vector.iter().fold(f32::MAX, |min, x| min.min(*x));

            println!("âœ… Vector properties:");
            println!("   Dimensions: {}", vector.len());
            println!("   Magnitude (normalized): {:.6}", magnitude);
            println!("   Has NaN: {}", has_nan);
            println!("   Has Inf: {}", has_inf);
            println!("   Is finite: {}", is_finite);
            println!("   Max value: {:.6}", max_value);
            println!("   Min value: {:.6}", min_value);

            // Assert vector properties
            assert_eq!(vector.len(), 384, "Vector should be 384 dimensions");
            assert!(!has_nan, "Normalized vector should not contain NaN");
            assert!(!has_inf, "Normalized vector should not contain Inf");
            assert!(is_finite, "All values should be finite");
            // Allow some tolerance for normalization differences between implementations
            let magnitude_diff = (magnitude - 1.0).abs();
            assert!(magnitude_diff < 0.01, "Normalized vector magnitude should be close to 1.0, got {}", magnitude);
            assert!(max_value >= 0.0, "Max value should be non-negative");
            assert!(min_value <= 0.0, "Min value should be non-positive");
        } else {
            panic!("No embedding generated for vector properties test");
        }
    }

    #[test]
    fn test_concurrent_embedding_generation() {
        println!("\nðŸ“‹ Test 8: Concurrent Embedding Generation");

        use std::sync::{Arc, Barrier};
        use std::thread;

        let client = Arc::new(std::sync::Mutex::new(gllm::Client::new("all-MiniLM-L6-v2")
            .expect("Failed to create gllm client")));

        let num_threads = 3;
        let texts_per_thread = 2;
        let barrier = Arc::new(Barrier::new(num_threads));

        let mut handles = vec![];

        for thread_id in 0..num_threads {
            let client_clone = Arc::clone(&client);
            let barrier_clone = Arc::clone(&barrier);

            let handle = thread::spawn(move || {
                barrier_clone.wait();

                let mut results = vec![];
                for i in 0..texts_per_thread {
                    let text = format!("Concurrent test thread {} text {}", thread_id, i + 1);

                    match client_clone.lock().unwrap().embeddings(&[text.clone()]).generate() {
                        Ok(response) => {
                            if let Some(emb) = response.embeddings.into_iter().next() {
                                let vector = normalize(&emb.embedding);
                                results.push((text, vector.len()));
                            }
                        }
                        Err(e) => {
                            eprintln!("Thread {} failed to generate embedding: {}", thread_id, e);
                        }
                    }
                }
                results
            });

            handles.push(handle);
        }

        let mut all_results = vec![];
        for handle in handles {
            let thread_results = handle.join().unwrap_or_else(|e| {
                panic!("Thread panicked: {:?}", e);
            });
            all_results.extend(thread_results);
        }

        println!("âœ… Concurrent embedding generation completed:");
        println!("   Generated {} embeddings", all_results.len());
        for (text, dims) in &all_results {
            println!("   '{}': {} dimensions", text, dims);
        }

        // Validate all embeddings
        assert_eq!(all_results.len(), num_threads * texts_per_thread,
                  "Should generate expected number of embeddings");

        for (_, dims) in all_results {
            assert_eq!(dims, 384, "All concurrent embeddings should be 384 dimensions");
        }
    }

    #[test]
    fn test_embedding_cache_behavior() {
        println!("\nðŸ“‹ Test 9: Model Cache Behavior");

        let client = gllm::Client::new("all-MiniLM-L6-v2")
            .expect("Failed to create gllm client");

        let test_text = "Cache behavior test";

        // Generate multiple embeddings to test caching
        let mut durations = vec![];
        for i in 0..3 {
            let start = std::time::Instant::now();

            let response = client.embeddings(&[test_text.to_string()]).generate()
                .expect("Embedding generation failed");

            let duration = start.elapsed();
            durations.push(duration);

            if let Some(emb) = response.embeddings.into_iter().next() {
                let vector = normalize(&emb.embedding);
                println!("âœ… Cache test run #{}: {:.3}ms, {} dimensions",
                       i + 1, duration.as_millis(), vector.len());
                assert_eq!(vector.len(), 384, "Cached embedding should be 384 dimensions");
            }
        }

        // Subsequent runs should be faster (cached model)
        if durations.len() >= 2 {
            let first_duration = durations[0];
            let second_duration = durations[1];

            println!("âœ… Cache performance:");
            println!("   First run: {:.3}ms", first_duration.as_millis());
            println!("   Second run: {:.3}ms", second_duration.as_millis());

            // Subsequent runs should be at least somewhat faster
            if second_duration < first_duration {
                println!("âœ… Cache working - second run was faster");
            } else {
                println!("âš ï¸  Cache notæ˜Žæ˜¾ - second run was not faster (may be first run)");
            }
        }
    }
}